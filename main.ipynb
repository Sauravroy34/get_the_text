{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4742d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from ocr_label_converter import OCRLabelConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409ea24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"\"\"Only thewigsofrcvdampbkuq.$A-210xT5'MDL,RYHJ\"ISPWENj&BC93VGFKz();#:!7U64Q8?+*ZX/%\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bc4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update SynthCollator to encode labels\n",
    "class SynthCollator(object):\n",
    "    def __init__(self, alphabet=alphabet):\n",
    "        self.converter = OCRLabelConverter(alphabet)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        width = [item['img'].shape[2] for item in batch]\n",
    "        indexes = [item['idx'] for item in batch]\n",
    "        imgs = torch.ones([len(batch), batch[0]['img'].shape[0], batch[0]['img'].shape[1], \n",
    "                           max(width)], dtype=torch.float32)\n",
    "        for idx, item in enumerate(batch):\n",
    "            try:\n",
    "                imgs[idx, :, :, 0:item['img'].shape[2]] = item['img']\n",
    "            except:\n",
    "                print(imgs.shape)\n",
    "        \n",
    "        # Encode labels\n",
    "        labels = [item['label'] for item in batch]\n",
    "        encoded_labels, label_lengths = self.converter.encode(labels)  # Encode all labels in the batch\n",
    "        \n",
    "        item = {\n",
    "            'img': imgs,  # (batch_size, 1, H, max_width)\n",
    "            'idx': indexes,\n",
    "            'label': encoded_labels,  # Tensor of encoded labels\n",
    "            'label_lengths': label_lengths  # Tensor of label lengths\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a8c49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom \n",
    "class Ocr_Dataset(Dataset):\n",
    "    def __init__(self,dir ,collate_fn = None):\n",
    "        self.dir = dir\n",
    "        self.imgpath = os.listdir(dir)\n",
    "        f = lambda x: os.path.join(self.dir, x)\n",
    "        self.images_path = list(map(f,self.imgpath))\n",
    "        transform_list =  [\n",
    "                            transforms.RandomRotation(5), \n",
    "                            transforms.Grayscale(1),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5,), (0.5,)) \n",
    "                            ]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "        \n",
    "        self.collate_fn = SynthCollator()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgpath)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images_path[index]\n",
    "        \n",
    "        image_name = os.path.basename(image_path)\n",
    "        img = Image.open(image_path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        item = {'img':img,'idx':index}\n",
    "        item[\"label\"] = image_name.split(\"_\")[0]\n",
    "        return item\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99498673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7043d44202f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = \"/home/saurav/Desktop/Get_The_Text/data/train\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "dataset = Ocr_Dataset(dir)\n",
    "len(dataset)\n",
    "\n",
    "img = np.asarray(dataset[0]['img'])  \n",
    "img = np.squeeze(img)\n",
    "plt.imshow(img,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "885e6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "    def forward(self, input):\n",
    "        self.rnn.flatten_parameters()\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "        return output\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = 1 if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6, True)  # 512x1x16\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential()\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, 256, 256),\n",
    "            BidirectionalLSTM(256, 256, len(alphabet)))\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        conv = self.cnn(input)\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "        output = output.transpose(1,0) #Tbh to bth\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8c5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCTCLoss(torch.nn.Module):\n",
    "    # T x B x H => Softmax on dimension 2\n",
    "    def __init__(self, dim=2):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.ctc_loss = torch.nn.CTCLoss(reduction='mean', zero_infinity=True)\n",
    "\n",
    "    def forward(self, logits, labels,\n",
    "            prediction_sizes, target_sizes):\n",
    "        EPS = 1e-7\n",
    "        loss = self.ctc_loss(logits, labels, prediction_sizes, target_sizes)\n",
    "        loss = self.sanitize(loss)\n",
    "        return self.debug(loss, logits, labels, prediction_sizes, target_sizes)\n",
    "    \n",
    "    def sanitize(self, loss):\n",
    "        EPS = 1e-7\n",
    "        if abs(loss.item() - float('inf')) < EPS:\n",
    "            return torch.zeros_like(loss)\n",
    "        if math.isnan(loss.item()):\n",
    "            return torch.zeros_like(loss)\n",
    "        return loss\n",
    "\n",
    "    def debug(self, loss, logits, labels,\n",
    "            prediction_sizes, target_sizes):\n",
    "        if math.isnan(loss.item()):\n",
    "            print(\"Loss:\", loss)\n",
    "            print(\"logits:\", logits)\n",
    "            print(\"labels:\", labels)\n",
    "            print(\"prediction_sizes:\", prediction_sizes)\n",
    "            print(\"target_sizes:\", target_sizes)\n",
    "            raise Exception(\"NaN loss obtained. But why?\")\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232b0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits,target,pred_size,target_size):\n",
    "    return CustomCTCLoss(logits,target,pred_size,target_size)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01a38ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurav/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: torch.Size([32, 1, 32, 124])\n",
      "Encoded labels shape: torch.Size([214])\n",
      "Label lengths: tensor([12,  9,  3,  7,  6,  8,  4,  6,  6,  7,  9,  8,  6,  6,  4,  4,  8,  5,\n",
      "         6,  4,  5,  8, 10, 11,  6,  7,  5,  9,  4,  9,  6,  6],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=SynthCollator()\n",
    ")\n",
    "for batch in train_dataloader:\n",
    "    images = batch['img']  # (batch_size, 1, H, max_width)\n",
    "    labels = batch['label']  # Encoded labels tensor\n",
    "    label_lengths = batch['label_lengths']  # Tensor of label lengths\n",
    "    print(f\"Batch images shape: {images.shape}\")\n",
    "    print(f\"Encoded labels shape: {labels.shape}\")\n",
    "    print(f\"Label lengths: {label_lengths}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f42a1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 2.2862\n",
      "Epoch [2/10], Average Loss: 0.1431\n",
      "Epoch [3/10], Average Loss: 0.0369\n",
      "Epoch [4/10], Average Loss: 0.0205\n",
      "Epoch [5/10], Average Loss: 0.0200\n",
      "Epoch [6/10], Average Loss: 0.0116\n",
      "Epoch [7/10], Average Loss: 0.0122\n",
      "Epoch [8/10], Average Loss: 0.0153\n",
      "Epoch [9/10], Average Loss: 0.0106\n",
      "Epoch [10/10], Average Loss: 0.0083\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model\n",
    "model = CRNN().to(device)\n",
    "model.train()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = CustomCTCLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        # Get the batch data\n",
    "        images = batch['img'].to(device)  # (actual_batch_size, 1, H, max_width)\n",
    "        labels = batch['label'].to(device)  # Encoded labels\n",
    "        label_lengths = batch['label_lengths'].to(device)  # (actual_batch_size,)\n",
    "        \n",
    "        # Get the actual batch size from the batch\n",
    "        actual_batch_size = images.shape[0]\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)  # (actual_batch_size, T, num_classes)\n",
    "        \n",
    "        # CTC loss expects (T, batch_size, num_classes)\n",
    "        logits = logits.transpose(0, 1)  # (T, actual_batch_size, num_classes)\n",
    "        log_probs = logits.log_softmax(2)  # Apply log_softmax for CTC\n",
    "        \n",
    "        # Get the actual sequence length T from log_probs\n",
    "        T, _, _ = log_probs.shape  # T is the actual sequence length\n",
    "        prediction_sizes = torch.full((actual_batch_size,), T, dtype=torch.long).to(device)\n",
    "        \n",
    "        # Debugging: Ensure prediction_sizes values are valid\n",
    "        if (prediction_sizes > T).any():\n",
    "            raise ValueError(f\"prediction_sizes contains values greater than T={T}: {prediction_sizes}\")\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(log_probs, labels, prediction_sizes, label_lengths)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a22d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"ocr_model_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b37cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu4): ReLU(inplace=True)\n",
       "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu5): ReLU(inplace=True)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu6): ReLU(inplace=True)\n",
       "  )\n",
       "  (rnn): Sequential(\n",
       "    (0): BidirectionalLSTM(\n",
       "      (rnn): LSTM(512, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (1): BidirectionalLSTM(\n",
       "      (rnn): LSTM(256, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=81, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = CRNN()\n",
    "test_model.load_state_dict(torch.load(\"ocr_model_final.pth\",weights_only=True))\n",
    "\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5f405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
